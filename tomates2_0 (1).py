# -*- coding: utf-8 -*-
"""Tomates2.0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hSPsH4xH4fiS71QZZm62rYwLg3U3YZ4d
"""

# 1. Instalar y descargar
#!pip install kagglehub tensorflow

import kagglehub
import os

# Descargar dataset
path = kagglehub.dataset_download("enalis/tomatoes-dataset")
print("Path to dataset files:", path)

# Definir rutas de entrenamiento y validaci√≥n
train_path = os.path.join(path, 'content/ieee-mbl-cls/train')
val_path = os.path.join(path, 'content/ieee-mbl-cls/val')

# 2. Importar librer√≠as y configurar constantes
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.applications import ResNet50, EfficientNetB0, MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, RandomFlip, RandomRotation, RandomZoom
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
import numpy as np
import matplotlib.pyplot as plt

IMG_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 15

print("Librer√≠as cargadas correctamente.")

# 3. Cargar datasets SIN normalizar (Raw data)

train_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    train_path,
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    shuffle=True
)

val_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    val_path,
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    shuffle=False
)

# Obtener nombres de clases
class_names = train_dataset.class_names
num_classes = len(class_names)
print(f"Clases ({num_classes}): {class_names}")

# Optimizar rendimiento (Cache y Prefetch)
AUTOTUNE = tf.data.AUTOTUNE
train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)
val_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)

print("Datos cargados y optimizados (formato crudo 0-255) ‚úì")

# 4. Definir Data Augmentation y Funci√≥n Constructora

# Aumento de datos: ayuda a que el modelo no falle con fotos rotadas o con zoom
data_augmentation = keras.Sequential([
    RandomFlip("horizontal_and_vertical"),
    RandomRotation(0.2),
    RandomZoom(0.1),
])

def crear_modelo_robusto(base_model, num_classes, model_name, preprocess_func):
    """
    Crea un modelo con Augmentation y Preprocesamiento espec√≠fico
    """
    base_model.trainable = False # Congelar modelo base

    inputs = keras.Input(shape=(224, 224, 3))

    # A. Data Augmentation (Solo activo durante entrenamiento)
    x = data_augmentation(inputs)

    # B. Preprocesamiento OBLIGATORIO espec√≠fico de cada red
    # Esto transforma los p√≠xeles exactamente como la red lo necesita (ej: -1 a 1, o caffe style)
    x = preprocess_func(x)

    # C. Pasar por el modelo base
    x = base_model(x, training=False)

    # D. Capas de clasificaci√≥n (Head)
    x = GlobalAveragePooling2D()(x)
    x = Dropout(0.4)(x) # Dropout m√°s alto para reducir overfitting
    x = Dense(256, activation='relu')(x)
    x = Dropout(0.3)(x)
    outputs = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs, outputs, name=model_name)
    return model

# Configurar Callbacks
def obtener_callbacks(nombre_modelo):
    checkpoint_dir = f'checkpoints/{nombre_modelo}'
    os.makedirs(checkpoint_dir, exist_ok=True)
    return [
        EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True, verbose=1),
        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1),
        ModelCheckpoint(f'{checkpoint_dir}/best_model.keras', monitor='val_accuracy', save_best_only=True)
    ]

print("Funci√≥n de modelado lista ‚úì")

# 5. Configurar ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess

print("Construyendo ResNet50...")
base_resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Pasamos 'resnet_preprocess' para arreglar el problema de accuracy bajo
modelo_resnet = crear_modelo_robusto(base_resnet, num_classes, 'ResNet50', resnet_preprocess)

modelo_resnet.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
print("ResNet50 listo.")

# 6. Configurar EfficientNetB0
from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess

print("Construyendo EfficientNetB0...")
base_efficient = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

modelo_efficient = crear_modelo_robusto(base_efficient, num_classes, 'EfficientNetB0', eff_preprocess)

modelo_efficient.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
print("EfficientNetB0 listo.")

# 7. Configurar MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mob_preprocess

print("Construyendo MobileNetV2...")
base_mobile = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

modelo_mobile = crear_modelo_robusto(base_mobile, num_classes, 'MobileNetV2', mob_preprocess)

modelo_mobile.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
print("MobileNetV2 listo.")

# 8. Entrenar todos los modelos

print("--- INICIANDO ENTRENAMIENTO RESNET ---")
h_resnet = modelo_resnet.fit(
    train_dataset, validation_data=val_dataset,
    epochs=EPOCHS, callbacks=obtener_callbacks('ResNet50')
)

print("\n--- INICIANDO ENTRENAMIENTO EFFICIENTNET ---")
h_efficient = modelo_efficient.fit(
    train_dataset, validation_data=val_dataset,
    epochs=EPOCHS, callbacks=obtener_callbacks('EfficientNetB0')
)

print("\n--- INICIANDO ENTRENAMIENTO MOBILENET ---")
h_mobile = modelo_mobile.fit(
    train_dataset, validation_data=val_dataset,
    epochs=EPOCHS, callbacks=obtener_callbacks('MobileNetV2')
)

# 9. Comparar resultados
plt.figure(figsize=(10, 6))
plt.plot(h_resnet.history['val_accuracy'], label='ResNet50 Val Acc')
plt.plot(h_efficient.history['val_accuracy'], label='EfficientNet Val Acc')
plt.plot(h_mobile.history['val_accuracy'], label='MobileNet Val Acc')
plt.title('Comparaci√≥n de Exactitud (Validaci√≥n)')
plt.xlabel('√âpocas')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# 10. PRUEBA FINAL: Subir una imagen desconocida
from google.colab import files
from tensorflow.keras.utils import load_img, img_to_array

def predecir_imagen_externa():
    print("üîΩ Sube tu imagen de tomate (jpg/png) aqu√≠ üîΩ")
    uploaded = files.upload()

    for fn in uploaded.keys():
        # Cargar imagen
        path = fn
        img = load_img(path, target_size=(224, 224))

        # Mostrar imagen
        plt.imshow(img)
        plt.axis('off')
        plt.show()

        # Preparar imagen para el modelo
        img_array = img_to_array(img)
        img_batch = np.expand_dims(img_array, axis=0)

        print(f"\nüîé RESULTADOS DEL AN√ÅLISIS PARA: {fn}\n" + "="*40)

        # Lista de modelos a probar
        modelos = [
            ('ResNet50', modelo_resnet),
            ('EfficientNetB0', modelo_efficient),
            ('MobileNetV2', modelo_mobile)
        ]

        for nombre, modelo in modelos:
            pred = modelo.predict(img_batch, verbose=0)
            score = tf.nn.softmax(pred[0])
            clase_idx = np.argmax(score)
            clase_str = class_names[clase_idx]
            confianza = 100 * np.max(score)

            print(f"ü§ñ {nombre}:")
            print(f"   ‚Ü≥ Diagn√≥stico: {clase_str}")
            print(f"   ‚Ü≥ Confianza:   {confianza:.2f}%")
            print("-" * 20)

# Ejecutar la funci√≥n
predecir_imagen_externa()